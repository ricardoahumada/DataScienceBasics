{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pandas Avanzado - Ejemplos Pr√°cticos\n",
        "\n",
        "Este notebook contiene ejemplos ejecutables de los conceptos avanzados de pandas cubiertos en la teor√≠a.\n",
        "\n",
        "![![image.png](attachment:image.png)](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports necesarios\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Librer√≠as importadas exitosamente\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Ejemplo 1: Series Temporales y An√°lisis de Fechas\n\n![üìä Ejemplo 1: Series Temporales y An√°lisis de Fechas](imgs/series_temporales.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear datos de ejemplo para an√°lisis temporal\n",
        "dates = pd.date_range(start='2023-01-01', end='2023-12-31', freq='D')\n",
        "np.random.seed(42)\n",
        "\n",
        "# Datos de ventas con tendencia y estacionalidad\n",
        "ventas_data = {\n",
        "    'fecha': dates,\n",
        "    'ventas': 100 + np.cumsum(np.random.normal(0, 10, len(dates))) + 20 * np.sin(2 * np.pi * np.arange(len(dates)) / 365.25),\n",
        "    'categoria': np.random.choice(['A', 'B', 'C'], len(dates)),\n",
        "    'region': np.random.choice(['Norte', 'Sur', 'Este', 'Oeste'], len(dates))\n",
        "}\n",
        "\n",
        "df_temporal = pd.DataFrame(ventas_data)\n",
        "df_temporal['fecha'] = pd.to_datetime(df_temporal['fecha'])\n",
        "df_temporal.set_index('fecha', inplace=True)\n",
        "\n",
        "print(\"Dataset temporal creado:\")\n",
        "print(df_temporal.head())\n",
        "print(f\"\\nForma del dataset: {df_temporal.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Resampling - Agrupar por mes\n",
        "monthly_sales = df_temporal['ventas'].resample('M').sum()\n",
        "print(\"Ventas mensuales:\")\n",
        "print(monthly_sales.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rolling windows - Promedios m√≥viles\n",
        "df_temporal['ventas_ma7'] = df_temporal['ventas'].rolling(window=7).mean()\n",
        "df_temporal['ventas_ma30'] = df_temporal['ventas'].rolling(window=30).mean()\n",
        "\n",
        "print(\"Datos con promedios m√≥viles:\")\n",
        "print(df_temporal[['ventas', 'ventas_ma7', 'ventas_ma30']].head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# An√°lisis de diferencias y cambios porcentuales\n",
        "df_temporal['ventas_diff'] = df_temporal['ventas'].diff()\n",
        "df_temporal['ventas_pct_change'] = df_temporal['ventas'].pct_change()\n",
        "\n",
        "print(\"An√°lisis de cambios:\")\n",
        "print(df_temporal[['ventas', 'ventas_diff', 'ventas_pct_change']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîó Ejemplo 2: An√°lisis de Correlaciones\n\n![üîó Ejemplo 2: An√°lisis de Correlaciones](imgs/correlaciones.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear dataset con variables correlacionadas\n",
        "np.random.seed(123)\n",
        "n_samples = 1000\n",
        "\n",
        "data_corr = {\n",
        "    'ventas': np.random.normal(1000, 200, n_samples),\n",
        "    'marketing': np.random.normal(500, 100, n_samples),\n",
        "    'temperatura': np.random.normal(20, 5, n_samples),\n",
        "    'ventas_altas': 100 + 0.8 * np.random.normal(1000, 200, n_samples) + np.random.normal(0, 50, n_samples)\n",
        "}\n",
        "\n",
        "df_corr = pd.DataFrame(data_corr)\n",
        "\n",
        "print(\"Dataset para an√°lisis de correlaciones:\")\n",
        "print(df_corr.head())\n",
        "print(f\"\\nEstad√≠sticas descriptivas:\")\n",
        "print(df_corr.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Matriz de correlaci√≥n\n",
        "correlation_matrix = df_corr.corr()\n",
        "print(\"Matriz de correlaci√≥n:\")\n",
        "print(correlation_matrix.round(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identificar variables altamente correlacionadas\n",
        "high_corr_pairs = []\n",
        "for i in range(len(correlation_matrix.columns)):\n",
        "    for j in range(i+1, len(correlation_matrix.columns)):\n",
        "        corr_value = correlation_matrix.iloc[i, j]\n",
        "        if abs(corr_value) > 0.5:  # Umbral de correlaci√≥n alta\n",
        "            high_corr_pairs.append((\n",
        "                correlation_matrix.columns[i], \n",
        "                correlation_matrix.columns[j], \n",
        "                corr_value\n",
        "            ))\n",
        "\n",
        "print(\"Pares de variables altamente correlacionadas (|r| > 0.5):\")\n",
        "for var1, var2, corr in high_corr_pairs:\n",
        "    print(f\"{var1} - {var2}: {corr:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç Ejemplo 3: Valores Faltantes y Imputaci√≥n\n\n![üîç Ejemplo 3: Valores Faltantes y Imputaci√≥n](imgs/valores_faltantes.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear dataset con valores faltantes\n",
        "np.random.seed(456)\n",
        "df_missing = pd.DataFrame({\n",
        "    'categoria': np.random.choice(['A', 'B', 'C'], 1000),\n",
        "    'region': np.random.choice(['Norte', 'Sur', 'Este', 'Oeste'], 1000),\n",
        "    'ventas': np.random.normal(1000, 200, 1000),\n",
        "    'precio': np.random.normal(50, 10, 1000),\n",
        "    'descuento': np.random.normal(0.1, 0.05, 1000)\n",
        "})\n",
        "\n",
        "# Introducir valores faltantes de forma selectiva\n",
        "df_missing.loc[np.random.choice(df_missing.index, 100, replace=False), 'ventas'] = np.nan\n",
        "df_missing.loc[np.random.choice(df_missing.index, 80, replace=False), 'precio'] = np.nan\n",
        "df_missing.loc[np.random.choice(df_missing.index, 60, replace=False), 'descuento'] = np.nan\n",
        "\n",
        "print(\"Dataset con valores faltantes:\")\n",
        "print(df_missing.info())\n",
        "print(\"\\nPorcentaje de valores faltantes por columna:\")\n",
        "missing_percent = (df_missing.isnull().sum() / len(df_missing)) * 100\n",
        "print(missing_percent.round(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imputaci√≥n por grupos\n",
        "print(\"Ejemplo de imputaci√≥n por categor√≠a:\")\n",
        "ventas_by_category = df_missing.groupby('categoria')['ventas'].mean()\n",
        "print(\"Ventas promedio por categor√≠a:\")\n",
        "print(ventas_by_category)\n",
        "\n",
        "# Aplicar imputaci√≥n\n",
        "df_imputed = df_missing.copy()\n",
        "df_imputed['ventas'] = df_imputed['ventas'].fillna(\n",
        "    df_imputed.groupby('categoria')['ventas'].transform('mean')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interpolaci√≥n temporal (para datos con √≠ndice temporal)\n",
        "# Crear datos con fechas\n",
        "dates_missing = pd.date_range(start='2023-01-01', periods=100, freq='D')\n",
        "df_temporal_missing = pd.DataFrame({\n",
        "    'fecha': dates_missing,\n",
        "    'ventas': np.random.normal(100, 20, 100)\n",
        "})\n",
        "\n",
        "# Introducir valores faltantes\n",
        "df_temporal_missing.loc[np.random.choice(df_temporal_missing.index, 20, replace=False), 'ventas'] = np.nan\n",
        "df_temporal_missing.set_index('fecha', inplace=True)\n",
        "\n",
        "print(\"Datos antes de interpolaci√≥n:\")\n",
        "print(df_temporal_missing.head(10))\n",
        "\n",
        "# Aplicar interpolaci√≥n temporal\n",
        "df_temporal_missing['ventas_interpolated'] = df_temporal_missing['ventas'].interpolate(method='time')\n",
        "\n",
        "print(\"\\nDatos despu√©s de interpolaci√≥n:\")\n",
        "print(df_temporal_missing.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Ejemplo 4: Pivot Tables Complejas\n\n![üìä Ejemplo 4: Pivot Tables Complejas](imgs/pivot_tables.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear dataset para pivot tables\n",
        "np.random.seed(789)\n",
        "df_pivot = pd.DataFrame({\n",
        "    'fecha': pd.date_range('2023-01-01', periods=365, freq='D'),\n",
        "    'categoria': np.random.choice(['Electr√≥nicos', 'Ropa', 'Hogar'], 365),\n",
        "    'region': np.random.choice(['Norte', 'Sur', 'Este', 'Oeste'], 365),\n",
        "    'ventas': np.random.normal(1000, 300, 365),\n",
        "    'unidades': np.random.normal(100, 30, 365)\n",
        "})\n",
        "\n",
        "df_pivot['fecha'] = pd.to_datetime(df_pivot['fecha'])\n",
        "df_pivot['mes'] = df_pivot['fecha'].dt.month\n",
        "\n",
        "print(\"Dataset para pivot tables:\")\n",
        "print(df_pivot.head())\n",
        "print(f\"\\nForma del dataset: {df_pivot.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pivot table b√°sica\n",
        "pivot_basic = df_pivot.pivot_table(\n",
        "    index='categoria',\n",
        "    columns='region',\n",
        "    values='ventas',\n",
        "    aggfunc='sum'\n",
        ")\n",
        "\n",
        "print(\"Pivot table b√°sica - Ventas por Categor√≠a y Regi√≥n:\")\n",
        "print(pivot_basic.round(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pivot table con m√∫ltiples agregaciones\n",
        "pivot_multi = df_pivot.pivot_table(\n",
        "    index='categoria',\n",
        "    columns='region',\n",
        "    values=['ventas', 'unidades'],\n",
        "    aggfunc={'ventas': ['sum', 'mean'], 'unidades': ['sum', 'mean']},\n",
        "    fill_value=0\n",
        ")\n",
        "\n",
        "print(\"Pivot table con m√∫ltiples agregaciones:\")\n",
        "print(pivot_multi.round(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pivot table con totales\n",
        "pivot_with_totals = df_pivot.pivot_table(\n",
        "    index='categoria',\n",
        "    columns='region',\n",
        "    values='ventas',\n",
        "    aggfunc='sum',\n",
        "    margins=True,\n",
        "    margins_name='Total'\n",
        ")\n",
        "\n",
        "print(\"Pivot table con totales:\")\n",
        "print(pivot_with_totals.round(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üî§ Ejemplo 5: Manejo de Texto y Datos Categ√≥ricos\n\n![üî§ Ejemplo 5: Manejo de Texto y Datos Categ√≥ricos](imgs/visualizacion.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear dataset con datos de texto\n",
        "df_text = pd.DataFrame({\n",
        "    'email': [\n",
        "        'usuario1@gmail.com',\n",
        "        'admin@empresa.com',\n",
        "        'test@dominio.es',\n",
        "        'usuario2@yahoo.com'\n",
        "    ],\n",
        "    'telefono': [\n",
        "        '+34 123 456 789',\n",
        "        '123-456-7890',\n",
        "        '(555) 123-4567',\n",
        "        '555.123.4567'\n",
        "    ],\n",
        "    'descripcion': [\n",
        "        'Producto de ALTA CALIDAD',\n",
        "        'Art√≠culo en OFERTA especial',\n",
        "        'Nuevo producto disponible',\n",
        "        'Art√≠culo con descuento del 20%'\n",
        "    ],\n",
        "    'categoria': ['A', 'B', 'A', 'C']\n",
        "})\n",
        "\n",
        "print(\"Dataset con datos de texto:\")\n",
        "print(df_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Operaciones b√°sicas de texto\n",
        "df_text['email_lower'] = df_text['email'].str.lower()\n",
        "df_text['descripcion_clean'] = df_text['descripcion'].str.lower()\n",
        "df_text['descripcion_length'] = df_text['descripcion'].str.len()\n",
        "\n",
        "print(\"Operaciones b√°sicas de texto:\")\n",
        "print(df_text[['email', 'email_lower', 'descripcion_length']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extracci√≥n con expresiones regulares\n",
        "df_text['dominio'] = df_text['email'].str.extract(r'@([^.]+)')\n",
        "df_text['proveedor'] = df_text['email'].str.extract(r'@([^.]+)\\.')\n",
        "\n",
        "# Extraer n√∫meros de tel√©fono limpios\n",
        "df_text['telefono_limpio'] = df_text['telefono'].str.replace(r'[^\\d]', '', regex=True)\n",
        "\n",
        "print(\"Extracci√≥n con expresiones regulares:\")\n",
        "print(df_text[['email', 'dominio', 'proveedor', 'telefono', 'telefono_limpio']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ö° Ejemplo 6: Performance y Optimizaci√≥n\n\n![‚ö° Ejemplo 6: Performance y Optimizaci√≥n](imgs/performance.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear dataset grande para testing\n",
        "np.random.seed(101)\n",
        "n_rows = 100000\n",
        "\n",
        "df_large = pd.DataFrame({\n",
        "    'col1': np.random.randint(1, 100, n_rows),\n",
        "    'col2': np.random.randint(1, 100, n_rows),\n",
        "    'col3': np.random.randn(n_rows),\n",
        "    'categoria': np.random.choice(['A', 'B', 'C', 'D'], n_rows)\n",
        "})\n",
        "\n",
        "print(f\"Dataset creado con {n_rows:,} filas\")\n",
        "print(f\"Uso de memoria: {df_large.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demostrar operaciones vectorizadas vs loops\n",
        "import time\n",
        "\n",
        "print(\"Comparaci√≥n de performance:\")\n",
        "\n",
        "# M√©todo 1: Loop (m√°s lento)\n",
        "start_time = time.time()\n",
        "result_loop = []\n",
        "for i in range(len(df_large)):\n",
        "    result_loop.append(df_large.iloc[i]['col1'] * df_large.iloc[i]['col2'])\n",
        "loop_time = time.time() - start_time\n",
        "\n",
        "# M√©todo 2: Vectorizado (m√°s r√°pido)\n",
        "start_time = time.time()\n",
        "result_vectorized = df_large['col1'] * df_large['col2']\n",
        "vectorized_time = time.time() - start_time\n",
        "\n",
        "print(f\"Loop: {loop_time:.4f} segundos\")\n",
        "print(f\"Vectorizado: {vectorized_time:.4f} segundos\")\n",
        "print(f\"Mejora: {loop_time/vectorized_time:.1f}x m√°s r√°pido\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optimizaci√≥n de tipos de datos\n",
        "print(\"Optimizaci√≥n de tipos de datos:\")\n",
        "\n",
        "# Ver uso actual de memoria\n",
        "memory_before = df_large.memory_usage(deep=True).sum() / 1024**2\n",
        "print(f\"Memoria antes: {memory_before:.2f} MB\")\n",
        "\n",
        "# Optimizar tipos de datos\n",
        "df_optimized = df_large.copy()\n",
        "df_optimized['col1'] = df_optimized['col1'].astype('int16')\n",
        "df_optimized['col2'] = df_optimized['col2'].astype('int16')\n",
        "df_optimized['categoria'] = df_optimized['categoria'].astype('category')\n",
        "\n",
        "memory_after = df_optimized.memory_usage(deep=True).sum() / 1024**2\n",
        "print(f\"Memoria despu√©s: {memory_after:.2f} MB\")\n",
        "print(f\"Ahorro: {((memory_before - memory_after) / memory_before) * 100:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîó Ejemplo 7: Joins y Merges Avanzados\n\n![üîó Ejemplo 7: Joins y Merges Avanzados](imgs/joins.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear datasets para merge\n",
        "df_customers = pd.DataFrame({\n",
        "    'customer_id': [1, 2, 3, 4, 5],\n",
        "    'name': ['Ana', 'Luis', 'Mar√≠a', 'Carlos', 'Elena'],\n",
        "    'city': ['Madrid', 'Barcelona', 'Valencia', 'Sevilla', 'Bilbao']\n",
        "})\n",
        "\n",
        "df_orders = pd.DataFrame({\n",
        "    'order_id': [101, 102, 103, 104, 105, 106],\n",
        "    'customer_id': [1, 2, 1, 3, 6, 2],  # customer_id=6 no existe en customers\n",
        "    'amount': [150.50, 200.00, 75.25, 300.00, 50.00, 120.75],\n",
        "    'order_date': ['2023-01-15', '2023-01-16', '2023-01-17', \n",
        "                   '2023-01-18', '2023-01-19', '2023-01-20']\n",
        "})\n",
        "\n",
        "print(\"Dataset de clientes:\")\n",
        "print(df_customers)\n",
        "print(\"\\nDataset de √≥rdenes:\")\n",
        "print(df_orders)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Diferentes tipos de merge\n",
        "print(\"INNER JOIN:\")\n",
        "inner_merge = pd.merge(df_customers, df_orders, on='customer_id', how='inner')\n",
        "print(inner_merge)\n",
        "\n",
        "print(\"\\nLEFT JOIN:\")\n",
        "left_merge = pd.merge(df_customers, df_orders, on='customer_id', how='left')\n",
        "print(left_merge)\n",
        "\n",
        "print(\"\\nRIGHT JOIN:\")\n",
        "right_merge = pd.merge(df_customers, df_orders, on='customer_id', how='right')\n",
        "print(right_merge)\n",
        "\n",
        "print(\"\\nOUTER JOIN:\")\n",
        "outer_merge = pd.merge(df_customers, df_orders, on='customer_id', how='outer')\n",
        "print(outer_merge)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Ejemplo 8: Detecci√≥n de Outliers\n\n![üéØ Ejemplo 8: Detecci√≥n de Outliers](imgs/outliers.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear dataset con outliers\n",
        "np.random.seed(202)\n",
        "normal_data = np.random.normal(100, 15, 1000)\n",
        "outliers = np.array([200, 250, -50, 300, 180])  # Valores extremos\n",
        "data_with_outliers = np.concatenate([normal_data, outliers])\n",
        "\n",
        "df_outliers = pd.DataFrame({\n",
        "    'valor': data_with_outliers,\n",
        "    'categoria': np.random.choice(['A', 'B', 'C'], len(data_with_outliers))\n",
        "})\n",
        "\n",
        "print(f\"Dataset con {len(data_with_outliers)} valores (incluye outliers)\")\n",
        "print(\"Estad√≠sticas descriptivas:\")\n",
        "print(df_outliers['valor'].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detecci√≥n de outliers usando IQR\n",
        "Q1 = df_outliers['valor'].quantile(0.25)\n",
        "Q3 = df_outliers['valor'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "print(f\"Q1: {Q1:.2f}\")\n",
        "print(f\"Q3: {Q3:.2f}\")\n",
        "print(f\"IQR: {IQR:.2f}\")\n",
        "print(f\"L√≠mite inferior: {lower_bound:.2f}\")\n",
        "print(f\"L√≠mite superior: {upper_bound:.2f}\")\n",
        "\n",
        "# Identificar outliers\n",
        "outliers_iqr = df_outliers[(df_outliers['valor'] < lower_bound) | \n",
        "                          (df_outliers['valor'] > upper_bound)]\n",
        "\n",
        "print(f\"\\nN√∫mero de outliers detectados: {len(outliers_iqr)}\")\n",
        "print(\"Valores outliers:\")\n",
        "print(outliers_iqr['valor'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tratamiento de outliers - winsorizing\n",
        "df_cleaned = df_outliers.copy()\n",
        "df_cleaned['valor_winsorized'] = df_cleaned['valor'].clip(\n",
        "    lower=lower_bound, \n",
        "    upper=upper_bound\n",
        ")\n",
        "\n",
        "print(\"Comparaci√≥n antes y despu√©s del winsorizing:\")\n",
        "comparison = pd.DataFrame({\n",
        "    'Original': df_outliers['valor'].describe(),\n",
        "    'Winsorized': df_cleaned['valor_winsorized'].describe()\n",
        "})\n",
        "print(comparison.round(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Ejemplo 9: Visualizaci√≥n con Pandas\n\n![üìä Ejemplo 9: Visualizaci√≥n con Pandas](imgs/visualizacion.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear dataset para visualizaci√≥n\n",
        "np.random.seed(303)\n",
        "dates_viz = pd.date_range('2023-01-01', periods=100, freq='D')\n",
        "df_viz = pd.DataFrame({\n",
        "    'fecha': dates_viz,\n",
        "    'ventas': 100 + np.cumsum(np.random.normal(0, 5, 100)),\n",
        "    'marketing': 50 + np.random.normal(0, 10, 100),\n",
        "    'categoria': np.random.choice(['A', 'B', 'C'], 100)\n",
        "})\n",
        "df_viz.set_index('fecha', inplace=True)\n",
        "\n",
        "print(\"Dataset para visualizaci√≥n:\")\n",
        "print(df_viz.head())\n",
        "\n",
        "# Crear subplots\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "fig.suptitle('An√°lisis Visual con Pandas', fontsize=16)\n",
        "\n",
        "# Gr√°fico de l√≠nea\n",
        "df_viz['ventas'].plot(ax=axes[0,0], title='Ventas a lo largo del tiempo')\n",
        "axes[0,0].set_ylabel('Ventas')\n",
        "\n",
        "# Histograma\n",
        "df_viz['ventas'].plot.hist(ax=axes[0,1], bins=20, title='Distribuci√≥n de Ventas')\n",
        "axes[0,1].set_xlabel('Ventas')\n",
        "\n",
        "# Box plot por categor√≠a\n",
        "df_viz.boxplot(column='ventas', by='categoria', ax=axes[1,0])\n",
        "axes[1,0].set_title('Ventas por Categor√≠a')\n",
        "\n",
        "# Scatter plot\n",
        "df_viz.plot.scatter(x='marketing', y='ventas', ax=axes[1,1], title='Marketing vs Ventas')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üî¢ Ejemplo 10: MultiIndex y Estructuras Complejas\n\n![üî¢ Ejemplo 10: MultiIndex y Estructuras Complejas](imgs/multiindex.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear MultiIndex\n",
        "arrays = [\n",
        "    ['A', 'A', 'B', 'B', 'C', 'C'],\n",
        "    ['uno', 'dos', 'uno', 'dos', 'uno', 'dos']\n",
        "]\n",
        "index = pd.MultiIndex.from_arrays(arrays, names=['letra', 'numero'])\n",
        "\n",
        "df_multi = pd.DataFrame(\n",
        "    np.random.randn(6, 3),\n",
        "    index=index,\n",
        "    columns=['col1', 'col2', 'col3']\n",
        ")\n",
        "\n",
        "print(\"DataFrame con MultiIndex:\")\n",
        "print(df_multi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Acceso a MultiIndex\n",
        "print(\"Acceso por primer nivel ('A'):\")\n",
        "print(df_multi.loc['A'])\n",
        "\n",
        "print(\"\\nAcceso por ambos niveles ('A', 'uno'):\")\n",
        "print(df_multi.loc[('A', 'uno')])\n",
        "\n",
        "print(\"\\nCross-section por 'numero' = 'dos':\")\n",
        "print(df_multi.xs('dos', level='numero'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear pivot table con MultiIndex\n",
        "np.random.seed(404)\n",
        "df_multi_pivot = pd.DataFrame({\n",
        "    'year': [2022, 2022, 2023, 2023] * 3,\n",
        "    'quarter': [1, 2, 1, 2] * 3,\n",
        "    'region': ['Norte', 'Sur'] * 6,\n",
        "    'sales': np.random.randint(100, 1000, 12)\n",
        "})\n",
        "\n",
        "pivot_multi = df_multi_pivot.pivot_table(\n",
        "    index=['year', 'quarter'],\n",
        "    columns='region',\n",
        "    values='sales',\n",
        "    aggfunc='sum'\n",
        ")\n",
        "\n",
        "print(\"Pivot table con MultiIndex en filas:\")\n",
        "print(pivot_multi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìù Resumen de Conceptos Cubiertos\n\n![üìù Resumen de Conceptos Cubiertos](imgs/visualizacion.png)\n\n\nEn este notebook hemos demostrado:\n\n‚úÖ **Series Temporales**: Resampling, rolling windows, an√°lisis de diferencias\n‚úÖ **Correlaciones**: Matrices de correlaci√≥n, identificaci√≥n de relaciones fuertes\n‚úÖ **Valores Faltantes**: Imputaci√≥n por grupos, interpolaci√≥n temporal\n‚úÖ **Pivot Tables**: Agregaciones m√∫ltiples, totales, funciones personalizadas\n‚úÖ **Procesamiento de Texto**: Expresiones regulares, limpieza de datos\n‚úÖ **Performance**: Operaciones vectorizadas, optimizaci√≥n de memoria\n‚úÖ **Joins**: Inner, left, right, outer joins con diferentes estrategias\n‚úÖ **Outliers**: Detecci√≥n IQR, tratamiento con winsorizing\n‚úÖ **Visualizaci√≥n**: M√∫ltiples tipos de gr√°ficos, subplots\n‚úÖ **MultiIndex**: Creaci√≥n, acceso, pivot tables complejas\n\nEstos conceptos son fundamentales para proyectos profesionales de data science y machine learning."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}